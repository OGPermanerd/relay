# Roadmap: EverySkill

## Milestones

- âœ… **v1.0 MVP** - Phases 1-8 (shipped 2026-01-31)
- âœ… **v1.1 Quality & Polish** - Phases 9-11 (shipped 2026-02-01)
- âœ… **v1.2 UI Redesign** - Phases 12-14 (shipped 2026-02-02)
- âœ… **v1.3 AI Quality & Cross-Platform** - Phases 15-19 (shipped 2026-02-04)
- âœ… **v1.4 Employee Analytics & Remote MCP** - Phases 20-24 (shipped 2026-02-06)
- âœ… **v1.5 Production, Multi-Tenancy & Reliable Usage Tracking** - Phases 25-33 (shipped 2026-02-08)
- âœ… **v2.0 Skill Ecosystem** - Phases 34-39 (shipped 2026-02-08)
- âœ… **v3.0 AI Discovery & Workflow Intelligence** - Phases 40-48 (shipped 2026-02-13)
- âœ… **v4.0 Gmail Workflow Diagnostic** - Phases 49-54 (shipped 2026-02-14)
- ðŸš§ **v5.0 Feedback, Training & Benchmarking** - Phases 55-61 (in progress)

## Phases

<details>
<summary>âœ… v1.0 MVP (Phases 1-8) - SHIPPED 2026-01-31</summary>

See archived roadmap: .planning/milestones/v1.0-ROADMAP.md

**Summary:**
- Phase 1: Project Foundation (4 plans)
- Phase 2: Authentication (3 plans)
- Phase 3: MCP Integration (6 plans)
- Phase 4: Data Model & Storage (5 plans)
- Phase 5: Skill Publishing (3 plans)
- Phase 6: Discovery (4 plans)
- Phase 7: Ratings & Reviews (3 plans)
- Phase 8: Metrics & Analytics (5 plans)

Total: 33 plans completed in 120 minutes.

</details>

<details>
<summary>âœ… v1.1 Quality & Polish (Phases 9-11) - SHIPPED 2026-02-01</summary>

See archived roadmap: .planning/milestones/v1.1-ROADMAP.md

**Summary:**
- Phase 9: Tag Filtering (1 plan)
- Phase 10: Quality Scorecards (4 plans)
- Phase 11: E2E Test Coverage (4 plans)

Total: 9 plans completed in 45 minutes.

</details>

<details>
<summary>âœ… v1.2 UI Redesign (Phases 12-14) - SHIPPED 2026-02-02</summary>

See archived roadmap: .planning/milestones/v1.2-ROADMAP.md

**Summary:**
- Phase 12: Two-Panel Layout Foundation (3 plans)
- Phase 13: Interactive Sorting & Accordion (4 plans)
- Phase 14: Mobile & Accessibility Polish (5 plans)

Total: 12 plans completed.

</details>

<details>
<summary>âœ… v1.3 AI Quality & Cross-Platform (Phases 15-19) - SHIPPED 2026-02-04</summary>

See archived roadmap: .planning/milestones/v1.3-ROADMAP.md

**Summary:**
- Phase 15: Embeddings Foundation (4 plans)
- Phase 16: Similarity Detection (2 plans)
- Phase 17: AI Review Pipeline (3 plans)
- Phase 18: Fork-Based Versioning (2 plans)
- Phase 19: Cross-Platform Install (2 plans)

Total: 15 plans completed.

</details>

<details>
<summary>âœ… v1.4 Employee Analytics & Remote MCP (Phases 20-24) - SHIPPED 2026-02-06</summary>

See archived roadmap: .planning/milestones/v1.4-ROADMAP.md

**Summary:**
- Phase 20: API Key Management (7 plans)
- Phase 21: Employee Usage Tracking (6 plans)
- Phase 22: Web Remote MCP (3 plans)
- Phase 23: Analytics Dashboard (7 plans)
- Phase 24: Extended MCP Search (2 plans)

Total: 25 plans completed.

</details>

<details>
<summary>âœ… v1.5 Production, Multi-Tenancy & Reliable Usage Tracking (Phases 25-33) - SHIPPED 2026-02-08</summary>

See archived roadmap: .planning/milestones/v1.5-ROADMAP.md

**Summary:**
- Phase 25: Multi-Tenancy Schema & Audit Foundation (9 plans)
- Phase 26: Auth & Subdomain Routing (3 plans)
- Phase 27: Production Docker Deployment (4 plans)
- Phase 28: Hook-Based Usage Tracking (7 plans)
- Phase 29: Tenant-Scoped Analytics & MCP (3 plans)
- Phase 30: Branding & Navigation (7 plans)
- Phase 31: Skills & Upload Enhancements (6 plans)
- Phase 32: Admin Panel (6 plans)
- Phase 33: Email & Notifications (7 plans)

Total: 55 plans completed.

</details>

<details>
<summary>âœ… v2.0 Skill Ecosystem (Phases 34-39) - SHIPPED 2026-02-08</summary>

See archived roadmap: .planning/milestones/v2.0-ROADMAP.md

**Summary:**
- Phase 34: Review Pipeline Foundation (5 plans)
- Phase 35: AI Review Integration (3 plans)
- Phase 36: Admin Review UI (3 plans)
- Phase 37: Review Notifications (4 plans)
- Phase 38: Conversational MCP Discovery (4 plans)
- Phase 39: Fork Detection (4 plans)

Total: 23 plans completed. 44 requirements across 6 categories.

</details>

<details>
<summary>âœ… v3.0 AI Discovery & Workflow Intelligence (Phases 40-48) - SHIPPED 2026-02-13</summary>

See archived roadmap: .planning/milestones/v3.0-ROADMAP.md

**Summary:**
- Phase 40: Visibility Scoping (4 plans)
- Phase 41: Loom Video Integration (2 plans)
- Phase 42: MCP Tool Unification (2 plans)
- Phase 43: User Preferences (3 plans)
- Phase 44: Admin Global Skills (2 plans)
- Phase 45: Hybrid Search & Discovery (3 plans)
- Phase 46: Search Analytics (2 plans)
- Phase 47: Homepage Research (1 plan)
- Phase 48: Homepage Redesign (2 plans)

Total: 21 plans completed. 9 phases, 26 requirements.

</details>

<details>
<summary>âœ… v4.0 Gmail Workflow Diagnostic (Phases 49-54) - SHIPPED 2026-02-14</summary>

See archived roadmap: .planning/milestones/v4.0-ROADMAP.md

**Summary:**
- Phase 49: Tenant Resolution Cleanup (3 plans)
- Phase 50: Gmail OAuth Infrastructure (3 plans)
- Phase 51: Email Analysis Pipeline (5 plans)
- Phase 52: Diagnostic Dashboard (2 plans)
- Phase 53: Skill Recommendations (2 plans)
- Phase 54: Deployment Plan (2 plans)

Total: 17 plans completed. 6 phases, 22 requirements.

</details>

### v5.0 Feedback, Training & Benchmarking (In Progress)

**Milestone Goal:** Close the loop from skill usage to skill improvement -- capture feedback in Claude and on web, collect training data from authors and real usage, measure actual token/cost per skill, and show benchmarking dashboards by model.

**Phase Numbering:**
- Integer phases (55, 56, ...): Planned milestone work
- Decimal phases (55.1, 55.2): Urgent insertions (marked with INSERTED)

- [x] **Phase 55: Schema Foundation & Data Sanitization** - New tables, denormalized columns, and secret-stripping utilities âœ…
- [x] **Phase 56: In-Claude Feedback Collection** - Thumbs up/down via MCP with smart frequency gating âœ…
- [x] **Phase 57: Web Feedback & Suggestions** - Structured suggestion form with author review workflow âœ…
- [ ] **Phase 58: Training Data & Golden Dataset** - Author-seeded examples and usage capture with consent
- [ ] **Phase 59: Suggestion-to-Fork Pipeline** - Accepted suggestions become forks or inline versions
- [x] **Phase 60: Token/Cost Measurement** - Capture tokens, cost, latency, and model per skill execution âœ…
- [ ] **Phase 61: Benchmarking Dashboard** - Per-skill benchmark tab with charts, model comparison, and staleness detection

#### Phase 55: Schema Foundation & Data Sanitization
**Goal**: All new database tables exist with proper multi-tenancy, and a sanitization utility prevents secrets from entering feedback and tracking data
**Depends on**: Nothing (foundation for all v5.0 work)
**Requirements**: SCHEMA-01, SCHEMA-02, SCHEMA-03, SCHEMA-04, SCHEMA-05, SCHEMA-06, SCHEMA-07
**Success Criteria** (what must be TRUE):
  1. The `skill_feedback`, `token_measurements`, `benchmark_runs`, and `benchmark_results` tables exist in the database with proper indexes, foreign keys, and TypeScript types exported from the schema package
  2. The `skills` table has new denormalized columns (`total_feedback`, `positive_feedback_pct`, `avg_token_cost_microcents`) that default to zero and are queryable
  3. All new tables include `tenant_id` NOT NULL with RLS policies following the established multi-tenancy pattern from Phase 25
  4. A payload sanitization utility detects and strips known secret patterns (API keys, passwords, bearer tokens, connection strings) from arbitrary text input, with unit tests proving it catches common formats
**Plans:** 2 plans
Plans:
- [x] 55-01-PLAN.md -- Schema files, migrations, relations for all 4 new tables + skills aggregate columns âœ…
- [x] 55-02-PLAN.md -- Sanitization utility with TDD (secret detection and stripping) âœ…

#### Phase 56: In-Claude Feedback Collection
**Goal**: Users can give thumbs up/down feedback on skills directly in Claude, and feedback sentiment is visible on skill detail pages
**Depends on**: Phase 55 (skill_feedback table must exist)
**Requirements**: FDBK-01, FDBK-02, FDBK-03, FDBK-04, FDBK-05, FDBK-06
**Success Criteria** (what must be TRUE):
  1. User can invoke the MCP `feedback` action in Claude (via `everyskill action:feedback`) with a thumbs up/down vote and optional text comment, and the feedback is persisted to the database
  2. The PostToolUse hook injects `additionalContext` prompting Claude to ask the user for feedback with smart frequency -- on the first 3 uses of a skill, then every 10th use thereafter
  3. The `/api/feedback` endpoint validates incoming feedback with Zod, requires Bearer auth, and enforces rate limiting to prevent abuse
  4. Skill detail pages display feedback sentiment (e.g., "85% positive over last 30 days") derived from aggregated thumbs up/down votes
  5. Feedback trend data (positive/negative ratio over time) is visible in the skill's metrics section
**Plans:** 2 plans
Plans:
- [x] 56-01-PLAN.md -- DB service, API endpoint, middleware exemption, MCP feedback action handler âœ…
- [x] 56-02-PLAN.md -- PostToolUse feedback prompt hook + skill detail page sentiment display âœ…

#### Phase 57: Web Feedback & Suggestions
**Goal**: Users can submit structured improvement suggestions on skill pages, and authors can review and act on them
**Depends on**: Phase 55 (skill_feedback table must exist)
**Requirements**: SUGGEST-01, SUGGEST-02, SUGGEST-03, SUGGEST-04, SUGGEST-05, SUGGEST-06
**Success Criteria** (what must be TRUE):
  1. User can submit an improvement suggestion on any skill detail page, selecting a category (output quality, missing feature, error, performance, other) and severity (nice to have, important, critical)
  2. Skill author sees a list of pending suggestions on their skill with Accept, Dismiss, and Reply actions
  3. Suggestion status tracks through a lifecycle (open -> accepted -> dismissed -> implemented) and the current status is visible to both author and suggester
  4. Author receives a notification when a new suggestion is submitted on their skill
  5. Suggester receives a notification when their suggestion's status changes (accepted, dismissed, implemented)
**Plans:** 3 plans
Plans:
- [x] 57-01-PLAN.md -- DB service, server actions, notification type extensions (backend) âœ…
- [x] 57-02-PLAN.md -- Suggestion form component and tab extension (submission UI) âœ…
- [x] 57-03-PLAN.md -- Suggestion list and card components with author review actions (review UI) âœ…

#### Phase 58: Training Data & Golden Dataset
**Goal**: Authors can seed golden input/output examples for their skills, and real usage can be captured as training data with explicit consent
**Depends on**: Phase 55 (skill_feedback table with training_example type), Phase 57 (web UI patterns for skill detail page additions)
**Requirements**: TRAIN-01, TRAIN-02, TRAIN-03, TRAIN-04, TRAIN-05, TRAIN-06
**Success Criteria** (what must be TRUE):
  1. Author can add golden examples (input/expected_output pairs) on the skill detail page, and they are stored as `feedbackType='training_example'` records in the skill_feedback table
  2. Real usage data can be captured as training examples when the user has explicitly opted in, with a per-user consent toggle that defaults to off
  3. All captured training data is run through the sanitization utility before storage, stripping any detected secrets
  4. The skill detail page displays a training example count, and a tenant-level admin setting controls whether usage-based capture is available for that organization
**Plans:** 3 plans
Plans:
- [ ] 58-01-PLAN.md -- Migration, schema updates, DB service functions, and server action (backend foundation)
- [ ] 58-02-PLAN.md -- Training example form, list, tab extension, page wiring, and admin settings toggle (UI)
- [ ] 58-03-PLAN.md -- Usage capture in /api/track with dual consent gating and sanitization (usage capture)

#### Phase 59: Suggestion-to-Fork Pipeline
**Goal**: Accepted suggestions flow into concrete skill improvements via forks or inline version updates
**Depends on**: Phase 57 (suggestions must exist with Accept action)
**Requirements**: SFORK-01, SFORK-02, SFORK-03, SFORK-04
**Success Criteria** (what must be TRUE):
  1. Author can click "Accept & Fork" on a suggestion, creating a fork pre-populated with the suggestion context using the existing `forkSkill()` action
  2. For small changes, author can create a new skill version inline without a full fork, directly from the suggestion view
  3. Accepted suggestions link to the resulting fork or version, providing traceability from feedback to improvement
  4. Suggestion status automatically updates to "implemented" when the linked fork or version is published
**Plans:** 2 plans
Plans:
- [ ] 59-01-PLAN.md -- Schema migration (implementedBySkillId), DB services, Accept & Fork + Apply Inline server actions
- [ ] 59-02-PLAN.md -- Suggestion card UI buttons + auto-implement hooks in publish flows

#### Phase 60: Token/Cost Measurement
**Goal**: Every skill execution captures token usage, cost estimate, latency, and model name, with per-skill cost aggregation visible on detail pages
**Depends on**: Phase 55 (token_measurements table must exist)
**Requirements**: TOKEN-01, TOKEN-02, TOKEN-03, TOKEN-04, TOKEN-05, TOKEN-06
**Success Criteria** (what must be TRUE):
  1. Token counts (input + output) and model name are captured per skill execution via the PostToolUse hook or transcript parsing, and stored in the `token_measurements` table
  2. Cost estimation is calculated using a static Anthropic pricing table (model -> $/MTok) and stored as `estimatedCostMicrocents` for aggregation
  3. Latency (ms) is tracked per skill execution alongside token data
  4. The `/api/track` endpoint accepts optional `token_count`, `model_name`, and `latency_ms` fields in a backward-compatible extension of the existing payload schema
  5. Skill detail pages display per-skill cost aggregation (average cost per use, total estimated cost) derived from the token_measurements table
**Plans:** 3 plans
Plans:
- [x] 60-01-PLAN.md -- Pricing table, token measurement DB service, /api/track extension âœ…
- [x] 60-02-PLAN.md -- PostToolUse hook transcript parsing for token/model capture âœ…
- [x] 60-03-PLAN.md -- Skill detail page cost aggregation display âœ…

#### Phase 61: Benchmarking Dashboard
**Goal**: Each skill has a "Benchmark" tab showing cost, token, quality, and feedback metrics with model comparison and staleness detection
**Depends on**: Phase 56 (feedback sentiment data), Phase 60 (token/cost data)
**Requirements**: BENCH-01, BENCH-02, BENCH-03, BENCH-04, BENCH-05, BENCH-06, BENCH-07, BENCH-08
**Success Criteria** (what must be TRUE):
  1. Each skill detail page has a "Benchmark" tab displaying quick stats: average cost, average tokens, quality score, and feedback sentiment
  2. When multi-model data is available, a model comparison table shows side-by-side metrics (tokens, cost, quality) per model
  3. A cost trend chart (Recharts AreaChart) shows cost per use over time on the benchmark tab
  4. Admin can trigger a benchmark run that executes the skill's golden examples across models (Anthropic SDK required, OpenAI and Google AI SDKs optional), with async execution and polling for results
  5. Benchmark staleness is detected (90-day warning) with a "Re-benchmark" button that triggers a fresh run

**Plans**: TBD

#### Dependency Graph

```
Phase 55 (Schema Foundation) â”€â”€â”¬â”€â”€> Phase 56 (In-Claude Feedback) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚                                                 â”‚
                               â”œâ”€â”€> Phase 57 (Web Suggestions) â”€â”€â”¬â”€â”€> Phase 58 (Training Data)
                               â”‚                                 â”‚
                               â”‚                                 â””â”€â”€> Phase 59 (Suggestion-to-Fork)
                               â”‚
                               â””â”€â”€> Phase 60 (Token/Cost Measurement) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                                â”‚
                                                                    Phase 61 (Benchmarking Dashboard)
                                                                    depends on 56 + 60
```

**Parallel execution opportunities:**
- Wave 0: Phase 55 (Schema Foundation -- must be first)
- Wave 1: Phase 56 + Phase 57 + Phase 60 (In-Claude Feedback, Web Suggestions, Token/Cost -- all depend only on Phase 55, independent of each other)
- Wave 2: Phase 58 + Phase 59 (Training Data depends on 55+57, Suggestion-to-Fork depends on 57)
- Wave 3: Phase 61 (Benchmarking Dashboard -- depends on Phase 56 and Phase 60)

**Note:** Wave 1 has three parallel tracks. Phase 60 (Token/Cost) has the highest technical risk (transcript_path parsing is unverified). Starting it in Wave 1 gives maximum time for investigation and fallback strategies.

## Progress

**Execution Order:**
Phases execute respecting dependencies: 55 -> 56/57/60 (parallel) -> 58/59 (parallel) -> 61

| Phase | Milestone | Plans Complete | Status | Completed |
|-------|-----------|----------------|--------|-----------|
| 1-8 | v1.0 | 33/33 | Complete | 2026-01-31 |
| 9-11 | v1.1 | 9/9 | Complete | 2026-02-01 |
| 12-14 | v1.2 | 12/12 | Complete | 2026-02-02 |
| 15-19 | v1.3 | 15/15 | Complete | 2026-02-04 |
| 20-24 | v1.4 | 25/25 | Complete | 2026-02-06 |
| 25-33 | v1.5 | 55/55 | Complete | 2026-02-08 |
| 34-39 | v2.0 | 23/23 | Complete | 2026-02-08 |
| 40-48 | v3.0 | 21/21 | Complete | 2026-02-13 |
| 49-54 | v4.0 | 17/17 | Complete | 2026-02-14 |
| 55. Schema Foundation | v5.0 | 2/2 | Complete | 2026-02-15 |
| 56. In-Claude Feedback | v5.0 | 2/2 | Complete | 2026-02-15 |
| 57. Web Suggestions | v5.0 | 3/3 | Complete | 2026-02-15 |
| 58. Training Data | v5.0 | 0/3 | Planned | - |
| 59. Suggestion-to-Fork | v5.0 | 0/2 | Planned | - |
| 60. Token/Cost Measurement | v5.0 | 3/3 | Complete | 2026-02-15 |
| 61. Benchmarking Dashboard | v5.0 | 0/TBD | Not started | - |

**Total: 220 plans completed across 57 phases and 9 milestones. v5.0: 10 plans, 4/7 phases complete.**

---
*Roadmap created: 2026-01-31*
*v1.0 completed: 2026-01-31*
*v1.1 completed: 2026-02-01*
*v1.2 completed: 2026-02-02*
*v1.3 completed: 2026-02-04*
*v1.4 completed: 2026-02-06*
*v1.5 completed: 2026-02-08*
*v2.0 completed: 2026-02-08*
*v3.0 completed: 2026-02-13*
*v4.0 completed: 2026-02-14*
*v5.0 roadmap created: 2026-02-15*
