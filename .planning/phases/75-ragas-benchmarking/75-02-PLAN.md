---
phase: 75-ragas-benchmarking
plan: 02
type: execute
wave: 2
depends_on: ["75-01"]
files_modified:
  - packages/db/src/services/benchmark.ts
  - packages/db/src/services/index.ts
  - apps/web/components/radar-dimension-chart.tsx
  - apps/web/components/benchmark-tab.tsx
  - apps/web/app/(protected)/skills/[slug]/page.tsx
autonomous: true

must_haves:
  truths:
    - "The benchmark results page displays a radar chart comparing dimension scores across models for a single benchmark run"
    - "A per-dimension model comparison table shows each model's dimension scores side-by-side"
    - "The skill's benchmark summary view shows aggregate dimension scores across all benchmark runs for that skill"
    - "Existing benchmark results with only an overall quality score continue to display correctly without errors or missing data"
    - "When only 1 model has dimension data, radar chart is not shown (requires 2+ models for meaningful comparison)"
  artifacts:
    - path: "packages/db/src/services/benchmark.ts"
      provides: "Extended ModelComparisonRow with dimension averages + getSkillDimensionAggregates function"
      contains: "avgFaithfulness"
    - path: "apps/web/components/radar-dimension-chart.tsx"
      provides: "Recharts RadarChart component for multi-model dimension comparison"
      contains: "RadarChart"
    - path: "apps/web/components/benchmark-tab.tsx"
      provides: "Extended BenchmarkTab with radar chart, dimension columns, and aggregate section"
      contains: "RadarDimensionChart"
    - path: "apps/web/app/(protected)/skills/[slug]/page.tsx"
      provides: "Data fetching for dimension aggregates passed to BenchmarkTab"
      contains: "getSkillDimensionAggregates"
  key_links:
    - from: "apps/web/app/(protected)/skills/[slug]/page.tsx"
      to: "packages/db/src/services/benchmark.ts"
      via: "getSkillDimensionAggregates() call"
      pattern: "getSkillDimensionAggregates"
    - from: "apps/web/components/benchmark-tab.tsx"
      to: "apps/web/components/radar-dimension-chart.tsx"
      via: "RadarDimensionChart component rendered conditionally"
      pattern: "RadarDimensionChart"
    - from: "packages/db/src/services/benchmark.ts"
      to: "packages/db/src/schema/benchmark-runs.ts"
      via: "SQL AVG queries on faithfulnessScore/relevancyScore/precisionScore/recallScore"
      pattern: "benchmarkResults\\.faithfulnessScore"
---

<objective>
Build the query layer and UI for 4-dimension benchmark visualization.

Purpose: Surface the per-dimension scores produced by Plan 01's extended judge in the UI -- radar chart for visual comparison, dimension columns in the model comparison table, and aggregate dimension scores per skill across benchmark runs.

Output: Extended query service, new RadarDimensionChart component, extended BenchmarkTab with dimension data, and updated skill page data fetching.
</objective>

<execution_context>
@/home/dev/.claude/get-shit-done/workflows/execute-plan.md
@/home/dev/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/75-ragas-benchmarking/75-01-SUMMARY.md
@packages/db/src/services/benchmark.ts
@apps/web/components/benchmark-tab.tsx
@apps/web/components/cost-trend-chart.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend query service with dimension averages and skill aggregates</name>
  <files>
    packages/db/src/services/benchmark.ts
    packages/db/src/services/index.ts
  </files>
  <action>
1. Extend `ModelComparisonRow` interface in `packages/db/src/services/benchmark.ts` with 4 dimension averages:
   ```typescript
   export interface ModelComparisonRow {
     modelName: string;
     avgQuality: number;
     avgFaithfulness: number;
     avgRelevancy: number;
     avgPrecision: number;
     avgRecall: number;
     avgCost: number;
     avgTokens: number;
     avgLatency: number;
     testCases: number;
   }
   ```

2. Extend the `getModelComparisonStats` query to include dimension averages. Add 4 new select fields after `avgQuality`:
   ```typescript
   avgFaithfulness: sql<number>`COALESCE(AVG(${benchmarkResults.faithfulnessScore}), 0)::int`,
   avgRelevancy: sql<number>`COALESCE(AVG(${benchmarkResults.relevancyScore}), 0)::int`,
   avgPrecision: sql<number>`COALESCE(AVG(${benchmarkResults.precisionScore}), 0)::int`,
   avgRecall: sql<number>`COALESCE(AVG(${benchmarkResults.recallScore}), 0)::int`,
   ```
   Note: For per-run model comparison, COALESCE to 0 is acceptable because if dimensions exist for new runs, all results in that run will have them. Old runs will show 0 and the UI conditionally hides dimension columns.

3. Add new `getSkillDimensionAggregates` function for BENCH-04. This aggregates dimension scores across ALL benchmark runs for a skill, filtering to only rows where dimension data exists (Pitfall 2 -- don't include old NULL results):
   ```typescript
   export interface SkillDimensionAggregates {
     avgFaithfulness: number;
     avgRelevancy: number;
     avgPrecision: number;
     avgRecall: number;
     runsWithDimensions: number;
   }

   export async function getSkillDimensionAggregates(
     skillId: string
   ): Promise<SkillDimensionAggregates | null> {
     if (!db) return null;

     const rows = await db
       .select({
         avgFaithfulness: sql<number>`AVG(${benchmarkResults.faithfulnessScore})::int`,
         avgRelevancy: sql<number>`AVG(${benchmarkResults.relevancyScore})::int`,
         avgPrecision: sql<number>`AVG(${benchmarkResults.precisionScore})::int`,
         avgRecall: sql<number>`AVG(${benchmarkResults.recallScore})::int`,
         runsWithDimensions: sql<number>`COUNT(DISTINCT ${benchmarkResults.benchmarkRunId})::int`,
       })
       .from(benchmarkResults)
       .innerJoin(benchmarkRuns, eq(benchmarkResults.benchmarkRunId, benchmarkRuns.id))
       .where(
         and(
           eq(benchmarkRuns.skillId, skillId),
           sql`${benchmarkResults.faithfulnessScore} IS NOT NULL`
         )
       );

     const result = rows[0];
     return result && result.runsWithDimensions > 0 ? result : null;
   }
   ```
   Import `benchmarkRuns` from schema if not already imported (it is already imported).

4. Update `packages/db/src/services/index.ts` to export the new function and type:
   Add `getSkillDimensionAggregates` to the function exports and `SkillDimensionAggregates` to the type exports from `"./benchmark"`.
  </action>
  <verify>
    - `pnpm turbo typecheck` passes
    - Verify ModelComparisonRow has 10 fields (was 6, now 10 with 4 new dimension averages)
    - Verify getSkillDimensionAggregates is exported from services/index.ts
    - After running a benchmark with dimension data (from Plan 01), verify `getModelComparisonStats` returns non-zero values for avgFaithfulness/avgRelevancy/avgPrecision/avgRecall by querying with the run ID of a run that has dimension data. Quick check: `SELECT AVG(faithfulness_score)::int FROM benchmark_results WHERE faithfulness_score IS NOT NULL` should return a non-zero value if any benchmark has been run with the new judge.
  </verify>
  <done>Query layer returns dimension averages per model in comparison stats, and aggregated dimension scores per skill across runs. NULL-dimension results are excluded from skill aggregates.</done>
</task>

<task type="auto">
  <name>Task 2: Radar chart component</name>
  <files>
    apps/web/components/radar-dimension-chart.tsx
  </files>
  <action>
Create NEW file `apps/web/components/radar-dimension-chart.tsx`. This is a "use client" component following the pattern established by `cost-trend-chart.tsx`.

```typescript
"use client";

import {
  RadarChart,
  Radar,
  PolarGrid,
  PolarAngleAxis,
  PolarRadiusAxis,
  Legend,
  ResponsiveContainer,
  Tooltip,
} from "recharts";

// Model colors for up to 4 models (extend if needed)
const MODEL_COLORS = ["#3b82f6", "#10b981", "#f59e0b", "#ef4444"];

interface ModelDimensionData {
  modelName: string;
  avgFaithfulness: number;
  avgRelevancy: number;
  avgPrecision: number;
  avgRecall: number;
}

interface RadarDimensionChartProps {
  models: ModelDimensionData[];
  height?: number;
}

// Short model name (matches benchmark-tab.tsx helper)
function shortModel(name: string): string {
  return name.replace(/^claude-/, "").replace(/-\d{8}$/, "");
}

export function RadarDimensionChart({ models, height = 300 }: RadarDimensionChartProps) {
  // Build radar data: one entry per dimension with a key per model
  const dimensions = ["Faithfulness", "Relevancy", "Precision", "Recall"] as const;
  const dimensionKeys: Record<typeof dimensions[number], keyof ModelDimensionData> = {
    Faithfulness: "avgFaithfulness",
    Relevancy: "avgRelevancy",
    Precision: "avgPrecision",
    Recall: "avgRecall",
  };

  const data = dimensions.map((dim) => {
    const point: Record<string, string | number> = { dimension: dim };
    for (const model of models) {
      point[shortModel(model.modelName)] = model[dimensionKeys[dim]];
    }
    return point;
  });

  return (
    <div style={{ height }} className="w-full">
      <ResponsiveContainer width="100%" height="100%">
        <RadarChart data={data} cx="50%" cy="50%" outerRadius="70%">
          <PolarGrid />
          <PolarAngleAxis dataKey="dimension" tick={{ fontSize: 12 }} />
          <PolarRadiusAxis angle={30} domain={[0, 100]} tick={{ fontSize: 10 }} />
          <Tooltip />
          <Legend />
          {models.map((model, i) => (
            <Radar
              key={model.modelName}
              name={shortModel(model.modelName)}
              dataKey={shortModel(model.modelName)}
              stroke={MODEL_COLORS[i % MODEL_COLORS.length]}
              fill={MODEL_COLORS[i % MODEL_COLORS.length]}
              fillOpacity={0.15}
            />
          ))}
        </RadarChart>
      </ResponsiveContainer>
    </div>
  );
}
```

Key design decisions:
- "use client" required for Recharts (Pitfall 4 from research)
- All data is integer 0-100 (no hydration risk from floats)
- Uses shortModel() matching existing benchmark-tab.tsx pattern
- fillOpacity=0.15 for overlapping polygons readability
- Domain fixed [0, 100] for consistent axis scale
  </action>
  <verify>
    - `pnpm turbo typecheck` passes
    - File exists at apps/web/components/radar-dimension-chart.tsx
    - Component exports RadarDimensionChart with correct props interface
  </verify>
  <done>RadarDimensionChart component renders a multi-model radar chart with 4 RAGAS dimensions, following established Recharts patterns.</done>
</task>

<task type="auto">
  <name>Task 3: Add dimension UI to BenchmarkTab</name>
  <files>
    apps/web/components/benchmark-tab.tsx
  </files>
  <action>
1. **Update BenchmarkTabProps** in `apps/web/components/benchmark-tab.tsx`:
   - Extend the `modelComparison` array type to include dimension averages:
     ```typescript
     modelComparison: {
       modelName: string;
       avgQuality: number;
       avgFaithfulness: number;
       avgRelevancy: number;
       avgPrecision: number;
       avgRecall: number;
       avgCost: number;
       avgTokens: number;
       avgLatency: number;
       testCases: number;
     }[];
     ```
   - Add new prop for skill-level dimension aggregates:
     ```typescript
     dimensionAggregates: {
       avgFaithfulness: number;
       avgRelevancy: number;
       avgPrecision: number;
       avgRecall: number;
       runsWithDimensions: number;
     } | null;
     ```

2. **Add RadarDimensionChart import** at top of benchmark-tab.tsx:
   ```typescript
   import { RadarDimensionChart } from "./radar-dimension-chart";
   ```

3. **Detect dimension data availability** inside the BenchmarkTab component body (after existing variable declarations):
   ```typescript
   const hasDimensionData = modelComparison.some(
     (row) => row.avgFaithfulness > 0 || row.avgRelevancy > 0
           || row.avgPrecision > 0 || row.avgRecall > 0
   );
   ```

4. **Add Radar Chart section (BENCH-02)** -- insert AFTER the "Model Comparison Table" section (section 4) and BEFORE the "Cost Trend Chart" section (section 5). Only render when dimension data exists AND 2+ models present (Pitfall 3 -- single model radar is useless):
   ```jsx
   {/* 4b. Dimension Radar Chart (BENCH-02) */}
   {hasDimensionData && modelComparison.length >= 2 && (
     <div className="rounded-lg border border-gray-200 bg-white p-4 space-y-3">
       <h3 className="text-sm font-semibold text-gray-800">Quality Dimensions</h3>
       <p className="text-xs text-gray-500">
         Per-dimension comparison across models (0-100 scale)
       </p>
       <RadarDimensionChart models={modelComparison} />
     </div>
   )}
   ```

5. **Add dimension columns to Model Comparison Table (BENCH-03)** -- extend the existing table in section 4:
   - Add 4 column headers after the "Quality" `<th>`, conditionally rendered:
     ```jsx
     {hasDimensionData && (
       <>
         <th className="pb-2 pr-4">Faith</th>
         <th className="pb-2 pr-4">Rel</th>
         <th className="pb-2 pr-4">Prec</th>
         <th className="pb-2 pr-4">Rec</th>
       </>
     )}
     ```
   - Add 4 data cells in each table row, after the Quality `<td>`, conditionally rendered:
     ```jsx
     {hasDimensionData && (
       <>
         <td className="py-2 pr-4 text-gray-600">{row.avgFaithfulness || "\u2014"}</td>
         <td className="py-2 pr-4 text-gray-600">{row.avgRelevancy || "\u2014"}</td>
         <td className="py-2 pr-4 text-gray-600">{row.avgPrecision || "\u2014"}</td>
         <td className="py-2 pr-4 text-gray-600">{row.avgRecall || "\u2014"}</td>
       </>
     )}
     ```
   Use em dash for 0-value dimensions to distinguish "not scored" from "scored 0."

6. **Add Skill Dimension Aggregates section (BENCH-04)** -- insert AFTER the radar chart section (4b) and BEFORE the cost trend section (5):
   ```jsx
   {/* 4c. Skill Dimension Aggregates (BENCH-04) */}
   {dimensionAggregates && (
     <div className="rounded-lg border border-gray-200 bg-white p-4 space-y-3">
       <h3 className="text-sm font-semibold text-gray-800">
         Aggregate Dimension Scores
       </h3>
       <p className="text-xs text-gray-500">
         Averaged across {dimensionAggregates.runsWithDimensions} benchmark run{dimensionAggregates.runsWithDimensions !== 1 ? "s" : ""} with dimension scoring
       </p>
       <div className="grid grid-cols-2 gap-4 lg:grid-cols-4">
         <StatCard label="Faithfulness" value={dimensionAggregates.avgFaithfulness} suffix="/100" />
         <StatCard label="Relevancy" value={dimensionAggregates.avgRelevancy} suffix="/100" />
         <StatCard label="Precision" value={dimensionAggregates.avgPrecision} suffix="/100" />
         <StatCard label="Recall" value={dimensionAggregates.avgRecall} suffix="/100" />
       </div>
     </div>
   )}
   ```

Backward compatibility (BENCH-05): All new UI sections are conditionally rendered. When `hasDimensionData` is false (old benchmark results), the page looks exactly as before. When `dimensionAggregates` is null, the aggregate section is hidden.
  </action>
  <verify>
    - `pnpm turbo typecheck` passes
    - `pnpm lint` passes
    - Verify BenchmarkTab renders without errors when modelComparison has no dimension data (backward compat)
  </verify>
  <done>
    - Radar chart displays when 2+ models have dimension data in a benchmark run (BENCH-02)
    - Model comparison table shows Faith/Rel/Prec/Rec columns when dimension data exists (BENCH-03)
    - Aggregate dimension scores section renders when dimensionAggregates is non-null (BENCH-04)
    - Pages with old benchmark data (no dimensions) render identically to before (BENCH-05)
  </done>
</task>

<task type="auto">
  <name>Task 4: Wire dimension data into skill page</name>
  <files>
    apps/web/app/(protected)/skills/[slug]/page.tsx
  </files>
  <action>
1. Add import for `getSkillDimensionAggregates` from `@everyskill/db/services`.

2. Fetch dimension aggregates in the existing parallel Promise.all (or as a separate await after it, since it depends on nothing):
   ```typescript
   const dimensionAggregates = await getSkillDimensionAggregates(skill.id);
   ```

3. Pass to BenchmarkTab:
   ```typescript
   <BenchmarkTab
     ...existing props...
     dimensionAggregates={dimensionAggregates}
   />
   ```
  </action>
  <verify>
    - `pnpm turbo typecheck` passes
    - `pnpm build` completes without errors (SSR + client bundle)
    - Run relevant Playwright tests: `cd apps/web && npx playwright test tests/e2e/skills.spec.ts` (if exists)
  </verify>
  <done>Skill page fetches dimension aggregates and passes them to BenchmarkTab. Full data pipeline from DB -> server component -> client component is wired.</done>
</task>

</tasks>

<verification>
- `pnpm turbo typecheck` passes across the monorepo
- `pnpm lint` passes
- `pnpm build` completes without errors
- Skill detail page loads without errors (Playwright or manual)
- BenchmarkTab renders correctly with no dimension data (backward compat)
- ModelComparisonRow type has 10 fields
- getSkillDimensionAggregates exported and callable
- RadarDimensionChart component exists and imports correctly
</verification>

<success_criteria>
1. The benchmark results page displays a radar chart comparing dimension scores across models (BENCH-02)
2. The model comparison table includes Faith/Rel/Prec/Rec columns when data is available (BENCH-03)
3. The skill benchmark summary shows aggregate dimension scores across all runs (BENCH-04)
4. Pages with pre-RAGAS benchmark results display identically to before -- no errors, no broken layout (BENCH-05)
5. Radar chart only renders with 2+ models (Pitfall 3)
6. Aggregate dimensions only include runs with dimension data, not old NULL results (Pitfall 2)
</success_criteria>

<output>
After completion, create `.planning/phases/75-ragas-benchmarking/75-02-SUMMARY.md`
</output>
